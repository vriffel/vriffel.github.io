[["index.html", "Modelo de regressão linear para precificação de processadores Prefácio", " Modelo de regressão linear para precificação de processadores Ana Rosária Zucon Vinicius Ricardo Riffel Prefácio Esse texto foi realizado na discplina CE071 (Análise de regressão linear) da UFPR ministrada pelo professor doutor Wagner Hugo Bonat e pelo professor doutor Walmes Marques Zeviani, ambos do Deparamento de Estatística da Universidade Federal do Paraná. A proposta dos professores foi construir um modelo de regressão linear a partir de dados coletados pelos alunos. Nós coletamos dados sobre anúncios de processadores de computadores de mesa em um site de vendas por meio da técnica de web scraping. Dentro das diversas variáveis que coletamos, identificamos que a quantidade de núcleos de processamento, ano de lançamento e frequência máxima do processador são variáveis que explicam bem a variação do preço dos anúncios. Os dados podem ser acessados pelo link: https://raw.githubusercontent.com/vriffel/data/main/processadores.csv "],["introdução.html", "1 Introdução", " 1 Introdução A compra de dispositivos tecnológicos é facilmente realizada através de sites de compra online. Antes o cliente estava acostumado a procurar soluções para sua vida tomando para si o que existia no mercado independente da adequação do produto ou serviço para seu propósito (Flores (2013)). Atualmente o mercado gamer é um dos mercados mais exigentes em termos de escolha de dispositivos tecnológicos de forma que atenda suas necessidades operacionais. Em 2018, somente esse mercado movimentou em média 1,5 bilhão de dólares no Brasil, sendo o Brasil o 13° maior mercado do mundo (Newzoo (2018)). Além do mercado de games também há nichos que exigem alta performance de seus dispositivos, como por exemplo empresas e pessoas que processam enorme quantidade de dados, softwares com alto custo computacional, entre outros. Segundo o site Tecmundo,1 em 2015, no caso do mercado de games, a experiência do jogo está diretamente ligada ao conjunto completo, de modo que a RAM, o processador, a placa-mãe, a placa de rede, a placa de som e todos os periféricos devem acompanhar a performance do chip gráfico. Nesse contexto, esses nichos são conhecidos por montar independentemente seus computadores, através da compra de peças isoladas e posterior montagem, de forma a obter um dispositivo otimizado para suas necessidades. O usuário deve estar atento às especificações técnicas do produto no momento da compra do seu equipamento, e não somente ao apelo visual (Lima, Jacques, and Bernandes (2020)). Dessa forma, um dos componentes determinantes para a qualidade de um computador é o processador. A decisão de compra de um processador envolve a checagem de diversos aspectos, tais como: marca, frequência de processamento, número de núcleos, RAM, potência etc. Intuitivamente, quanto maior a quantidade de recursos e capacidade de processamento, melhor o processador e maior valor monetário. Uma das formas mais usuais de checar se há relação entre variáveis é a partir de modelos de regressão. Os modelos de regressão são úteis situações em que é necessário quantificar a relação entre variáveis. Essas técnicas assumem que a variável resposta condicionada às covariáveis tem alguma distribuição de probabilidade. Uma vez que essa suposição é feita, conseguimos obter medidas dessa condicional (esperança, variância, quantil etc). A obtenção dessas medidas é feita por meio de alguma função das covariáveis e dos parâmetros do modelo. É importante ressaltar que os modelos regressão quantificam a associação entre as covariáveis e a variável reposta. Isto é, com ressalvas aos estudos experimentais, não podemos concluir que as covariáveis causam a variável resposta. Há um ramo da estatística que estuda essas relações de causação, mais detalhes podem ser visto em Pearl (2011). Dessa forma, o presente estudo teve como objetivo analisar, por meio de um modelo de regressão, a relação entre o preço do processador e 3 de suas características: ano de lançamento, frequência máxima de processamento (em GHz) e número de núcleos de processamento. https://www.tecmundo.com.br/video-game-e-jogos/86316-define-maquina-gamer.htm. Acessado em 23/03/2021↩︎ "],["material-e-métodos.html", "2 Material e métodos 2.1 Coleta de dados 2.2 Metodologia", " 2 Material e métodos 2.1 Coleta de dados Os dados foram coletados via web scrapping no site Mercado Livre usando o pacote rvest (Wickham (2020)) do software R (R Core Team (2021)) nos dias 03/03/2021 e 11/03/2021. Eles se referem a anúncios de processadores de computadores de mesa das marcas AMD e Intel. Como covariáveis utilizamos o ano de lançamento do processador, a frequência máxima de processamento (em GHz) e o número de núcleos de processamento. Embora não seja usada como covariável, mantívemos a marca dos processadores. Evidentemente, a variável resposta é o preço do processador. Na primeira amostragem, do dia 03/03/2021, selecionamos 670 anúncios. Porém, removemos 311 anúncios que estavam com dados faltantes ou não eram anúncios de processadores para computadores de mesa (a maioria deles eram kits que incluiam um processador, mas haviam processadores para celulares, notebooks e outros. Um problema recorrente encontrado foi o vendendor confundir a quantidade de threads e núcleos de processamento, para esses casos, nós assinalamos os valores corretos para os dados, checando a informação no site do fabricante). Nessa primeira amostragem, constatamos que o valor da variável resposta não estava inteiramente coberto, isto é, não havia dados suficientes para processadores com preço maior que 3,000 R$. Para ser preciso, apenas 21 observações. Para resolver esse problema, no dia 11/03/2021 coletamos mais dados, porém fixamos o preço mínimo dos anúncios em 3,000 R$. Nessa segunda amostragem, coletamos 155 dados com essa característica de preço, tomando o devido cuidado para não haver dados duplicados e removendo as observações indevidas, totalizando 514 observações. 2.2 Metodologia Nessa subseçao descrevemos as metodologias utilizadas para os ajustes dos modelos. Ela foi baseada tanto no material disponibilizados pelos professores quanto nos livros Faraway (2014) e Montgomery, Peck, and Vining (2006). Um modelo de regressão linear é uma método estatístico que procura identificar relações de associação entre as covariáveis e a variável resposta. Em nosso trabalho, buscamos obter o preço médio do preço dado o ano de lançamento, frequência máxima e número de núcleos de processamento do processados. Condicionando o preço essas covariáveis temos que: \\[ Y_i | \\mathbf{x}_i^t = \\beta_0 + \\beta_1x_{ifreq} + \\beta_2x_{inucleos} + \\beta_3x_{iano} + \\varepsilon_i \\hspace{0.2cm} i = 1, 2, \\ldots, n. \\] Então, a equação do modelo é da forma: \\[ E(Y_i | \\mathbf{x}_i^t) = \\hat{\\beta_0} + \\hat{\\beta_1}x_{ifreq} + \\hat{\\beta_2} x_{inucleos} + \\hat{\\beta_3} x_{iano} \\] Assumindo que: \\(E(\\varepsilon_i) = 0\\). \\(Var(\\varepsilon_i) = \\sigma^2\\) (constante). \\(Cov(\\varepsilon_i, \\varepsilon_j) = 0 \\hspace{0.2cm} i \\neq j\\). As covariáveis não são estocásticas. \\(\\varepsilon_i \\sim N(0, \\sigma^2)\\). A estimação pode ser feita pelo método dos mínimos quadrados ou máxima verossimilhanaça, ambas fornecerão os mesmos valores. Caso todas as premissas sejam verdadeiras, os estimadores obtidos por máxima verossimilhança ou mínimos quadrados são os melhores dentro da classe dos estimadores lineares (teorema de Gauss-Markov). Também, isso implacará que os estimadores terão distribuição (assintótica) Normal. Com isso, podemos construir intervalos de confiança e testes hipóteses das maneiras usuais. A partir disso, com a inferência sobre os parâmetros do modelo nos permite checar a significância do modelo, variáveis explicativas mais relevantes na análise e avaliar o erro de estimativas das predições geradas pelo modelo ajustado. Em algumas situações a relação entre a variável resposta \\(Y\\) e alguma covariável \\(X_k\\) não pode ser descrita por uma reta, mas por um polinômio de ordem \\(p\\). Neste caso, essa variável deverá ser adicionada ao modelo com seus termos de maior ordem. O modelo para uma covariável \\(X_k\\) fica dado por: \\[ E(Y_i | \\mathbf{x}_{ki}^t) = \\hat{\\beta_0} + \\hat{\\beta_1}x_{ki} + \\hat{\\beta_2} x_{ki}^2 + \\ldots + \\hat{\\beta_p} x_{ki}^p \\hspace{0.2cm} i = 1, 2, \\ldots, n. \\] isso é chamado de regressão polinomial. As premissas e os métodos de estimação mencionados anteriormente continuam os mesmos. A intepretação desse tipo de modelo fica limitada ao intervalo de estudo - a menos que seja conhecida a extrapolação do fenômeno. Uma vez que temos o modelo ajustado aos dados, devemos verificar a qualidade desse ajuste e se as premissas estão sendo cumpridas. Essa verificação é chamada de análise de diagnóstico. Ela pode ser realizada por inspeções gráficas e buscamos problemas como: Falta de ajuste: as covariáveis não são suficientes para explicar a variável resposta. Buscamos padrões sistemáticos que podem indicar especificação incorreta do preditor do modelo. Violações das premissas: relação entre média e variância nos resíduos (variância não constante); resíduos que não se adequam a uma distribuição Normal. Pontos influentes: observações (podem ser outliers ou não) que influciam para os valores estimados para os parâmetros, valores ajustados, variância do resíduo etc. A falta de ajuste e variância não constante podem ser verificadas por meio de um gráfico de resíduos vs valores ajustados. A normalidade pode-se checar por meio de um gráfico quantil-quantil. Os pontos influentes são identificados deixando uma observação de fora e ajustando o modelo novamente, estas medidas são chamadas de leave-one-out. Alguns dos casos em que as premissas são violadas há medidas que poder ser aplicadas ao modelo que diminuem o impacto da violação. Por exemplo, caso seja identificado que o modelo possuí variância não constante, as estimativas obtidas pelos métodos mencionados não são eficientes. Neste cenário, pode-se aplicar uma transformação nos dados que a deixe constante. Ou ainda, podemos aplicar uma transformação em nossa variável resposta para se obter normalidade nos resíduos, dentre inumeras medidas corretivas. A regressão robusta é um método útil para estimação na presença de outliers ou pontos com influência sobre os resultados. Essas observações modificam os valores estimados e/ou ajustados em função de sua atípicidade. Esses métodos adicionam uma função peso em que os erros são os argumentos na obtenção dos parâmetros estimados. Controla-se a magnitunidade dessa função peso por meio de um parâmetro de eficiência. Com isso, minimizamos o impacto das observações atípicas. A flexibilidade desse tipo de regressão recaí na definição função peso, na prática testamos várias dessas funções e verificamos qual produz o melhor ajuste. "],["resultados-e-dicussão.html", "3 Resultados e dicussão 3.1 Análise descritiva 3.2 Ajuste do modelo 3.3 Discussão", " 3 Resultados e dicussão 3.1 Análise descritiva A Figura 3.1 mostra um gráfico de pontos das variáveis da base versus as outras com uma reta ajustada via regressão linear simples, um gráfico de barras (ou histograma, para as variáveis contínuas) e o coeficiente de correlação produto-momento das variáveis. A base de dados contém 514 anúncios de processadores de computadores de mesa das marcas AMD e Intel. Há processadores com data de lançamento de 2005 até 2020. Na base há 205 observações de processadores AMD e 309 de processadores Intel. O preço está em R$ e a frequência máxima de processamento está em GHz. A variável preco_transformado é variável resposta após uma transformação raíz quinta. Nessa escala, os dados têm melhor comportamento do que na escala original, a correlação entre as variáveis teve uma melhoria e a variabilidade é menor. Encontramos esse valor através de método de Box-Cox (Box and Cox (1964)). Figura 3.1: Análise descritiva do conjunto de dados com uma reta ajustada via regressão linear simples entre as variáveis e o coeficiente de correlação de Pearson. Podemos ver que as covariáveis são correlacionadas linearmente entre si e correlacionadas com a variável resposta, essas correlações sempre positivas. Para o ajuste do modelo, vamos utilizar o preço transformado. Também, notamos que uma reta não é suficiente para explicar a relação entre a variável resposta e as demais covariáveis. A variável resposta é assimétrica em ambas escalas, porém com a transformação isso reduziu. Percebemos que há poucos anúncios de processadores com mais de 10 núcleos e de processadores mais antigos. Ainda, não parece haver diferença média significativa entre as marcas. 3.2 Ajuste do modelo Após testar diversos modelos, o que melhor se ajustou aos dados foi: \\[ E(Y_i | \\mathbf{x}_i^t) = \\hat{\\beta_0} + \\hat{\\beta_1}x_{ifreq} + \\hat{\\beta_2} x_{ifreq}^2 + \\hat{\\beta_3} x_{ifreq}^3 + \\hat{\\beta_4}x_{iano} + \\hat{\\beta_5} x_{iano}^2 + \\hat{\\beta_6} x_{iano}^3 + \\hat{\\beta_7} x_{inucleos} + \\hat{\\beta_8} x_{inucleos}^2 \\] No anexo do projeto encontra-se uma tabela comparando a critérios de qualidade de ajuste para diversos modelos ajustados aos dados. Ajustamos os modelos no software R (R Core Team (2021)). Utlizamos a função poly para encontrar polinômios ortogonais para as variáveis. A desvantagem de sua utilização é que a interpretação dos valores ajustados não é simples. O ajuste e resumo do modelo ajustado estão no Código 3.1: Código 3.1 Ajuste e resumo do modelo. dt &lt;- data.table::fread(&quot;../dados/processadores.csv&quot;, sep = &quot;;&quot;) ## Ajusta o modelo fit &lt;- lm(Preco^0.2 ~ poly(Freq, 3) + poly(Nucleos, 2) + poly(Ano, 3), data = dt) ## Resumo do ajuste summary(fit) ## ## Call: ## lm(formula = Preco^0.2 ~ poly(Freq, 3) + poly(Nucleos, 2) + poly(Ano, ## 3), data = dt) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.73608 -0.11750 -0.00553 0.12822 0.66145 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.192944 0.009105 460.510 &lt; 2e-16 *** ## poly(Freq, 3)1 9.107335 0.472834 19.261 &lt; 2e-16 *** ## poly(Freq, 3)2 0.639123 0.266753 2.396 0.01694 * ## poly(Freq, 3)3 -0.803299 0.244029 -3.292 0.00107 ** ## poly(Nucleos, 2)1 11.433445 0.302089 37.848 &lt; 2e-16 *** ## poly(Nucleos, 2)2 -2.599557 0.321110 -8.096 4.29e-15 *** ## poly(Ano, 3)1 3.700255 0.377977 9.790 &lt; 2e-16 *** ## poly(Ano, 3)2 -0.828141 0.253659 -3.265 0.00117 ** ## poly(Ano, 3)3 -2.512418 0.227228 -11.057 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.2064 on 505 degrees of freedom ## Multiple R-squared: 0.9577, Adjusted R-squared: 0.9571 ## F-statistic: 1430 on 8 and 505 DF, p-value: &lt; 2.2e-16 ## Tabela ANOVA anova(fit) ## Analysis of Variance Table ## ## Response: Preco^0.2 ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## poly(Freq, 3) 3 402.93 134.311 3152.005 &lt; 2.2e-16 *** ## poly(Nucleos, 2) 2 74.50 37.251 874.213 &lt; 2.2e-16 *** ## poly(Ano, 3) 3 10.02 3.341 78.407 &lt; 2.2e-16 *** ## Residuals 505 21.52 0.043 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Os resultados mostram que o modelo teve um bom ajuste. A quantidade explicada pela regressão (\\(R^2\\)) mostra que o modelo explicou bem a variação dos preços. Nota-se que o \\(R^2\\) ajustado (o que penaliza por número de parâmetros) ficou próximo ao valor não penalizado. Pelos valores do fator de inflação de variância generalizado, não há indício de multicolinearidade no ajuste. car::vif(fit) ## GVIF Df GVIF^(1/(2*Df)) ## poly(Freq, 3) 11.366183 3 1.499463 ## poly(Nucleos, 2) 3.616474 2 1.379022 ## poly(Ano, 3) 6.085672 3 1.351195 O modelo declarado não apresenta falta de ajuste, como pode ser visto nas Figuras 3.2 e 3.3. A Figura 3.3 mostra que a relação do tipo média-variância não está ideal. Também, os resíduos se adequaram bem à distribuição Normal, com fuga de alguns pontos nas caudas. A Figura 3.4 mostra que há pontos com alta alavancagem e influentes. As observações influentes não devem ser retiradas, uma vez que seus registros foram verificados e elas fazem parte da população de interesse. Além disso, há poucos poucas observações nos maiores valores do domínio do preço, como foi visto na análise descritiva dos dados. Nessa área, os resíduos parecem ter uma variância diferente dos anteriores. Figura 3.2: Análise de diagnóstico do primeiro modelo ajustado. Resíduos versus cada termo de maior ordem do modelo. Figura 3.3: Análise de diagnóstico do primeiro modelo ajustado. Resíduos versus valores ajustado (superior esquerda), raíz quadrada do valor absoluto dos resíduos padronizados (inferior esquerda), gráfico quantil-quantil dos resíduos (superior direita) e resíduos padronizados versus alavancagem (inferior direita). Figura 3.4: Análise de diagnóstico do primeiro modelo ajustado. Gráfico de influência dos resíduos. Quanto maior for o círculo, maior é a distância de Cook. ## StudRes Hat CookD ## 158 -3.380072 0.21226754 0.33515083 ## 276 -3.653400 0.02404898 0.03567219 ## 332 -1.368472 0.27655660 0.07940705 Figura 3.5: Análise de diagnósico do primeiro modelo ajustado. Outras medidas de influência para cada resíduo. 3.2.1 Medidas corretivas Para lidar com os pontos influentes, ajustamos uma regressão robusta com \\(\\psi_{Biweight}\\). Fixando a constante dessa regressão em \\(k = 4.685\\) para 95% de eficiência. Esse ajuste é feito no Código 3.2. Código 3.2 Regressão robusta com pesos \\(\\mathbf{\\psi_{Biweight}}\\) e ponderação na variância ## Ajusta o modelo fit2 &lt;- MASS::rlm(Preco^0.2 ~ poly(Freq, 3) + poly(Nucleos, 2) + poly(Ano, 3), data = dt, psi = MASS::psi.bisquare) Resumo do modelo: summary(fit2) ## ## Call: rlm(formula = Preco^0.2 ~ poly(Freq, 3) + poly(Nucleos, 2) + ## poly(Ano, 3), data = dt, psi = MASS::psi.bisquare) ## Residuals: ## Min 1Q Median 3Q Max ## -0.733963 -0.120638 -0.004154 0.129846 0.660298 ## ## Coefficients: ## Value Std. Error t value ## (Intercept) 4.1922 0.0092 456.9444 ## poly(Freq, 3)1 9.1225 0.4764 19.1475 ## poly(Freq, 3)2 0.5298 0.2688 1.9710 ## poly(Freq, 3)3 -0.8512 0.2459 -3.4616 ## poly(Nucleos, 2)1 11.4633 0.3044 37.6599 ## poly(Nucleos, 2)2 -2.6577 0.3236 -8.2140 ## poly(Ano, 3)1 3.7151 0.3809 9.7545 ## poly(Ano, 3)2 -0.7895 0.2556 -3.0887 ## poly(Ano, 3)3 -2.6392 0.2290 -11.5271 ## ## Residual standard error: 0.1799 on 505 degrees of freedom anova(fit2) ## Analysis of Variance Table ## ## Response: Preco^0.2 ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## poly(Freq, 3) 3 359.95 119.982 ## poly(Nucleos, 2) 2 67.46 33.732 ## poly(Ano, 3) 3 9.11 3.037 ## Residuals 21.56 Houve uma ligeira mudança nos valores dos parâmetros estimados, não iremos remover o coeficiente não significativo para (\\(\\alpha = 0.05\\)) pelo princípio da hierarquia. O diagnóstico dessa correção está na Figura 3.6. Com essa modificação, ainda constatamos um leve decaímento da variância com o aumento da média do preço. Os resíduos ainda aparentam ter distribuição Normal, com algumas fugas nas caudas. Ainda há pontos com influentes com alavancagem alta, porem em menor escala que o ajuste anterior. Também, notamos que com a modificação alguns pontos têm resíduos padronizados maiores que os anteriores, e até mesmo alguns candidatos a outlier. Não há razão para removê-los, uma vez que as observações são da população e não apresentam erro de registro. Figura 3.6: Análise de diagnóstico do segundo modelo ajustado. Resíduos versus valores ajustado (superior esquerda), raíz quadrada do valor absoluto dos resíduos padronizados (inferior esquerda), gráfico quantil-quantil dos resíduos (superior direita) e resíduos padronizados versus alavancagem (inferior direita). 3.3 Discussão Nessa seção fizemos a análise descritiva e quantitativa dos dados coletados. Logo na análise descritiva identificamos que a variável reposta estava em uma escala não adequada e aplicamos uma transformação Box-Cox que facilitou a construção posterior do modelo. Também constatamos que as covariáveis escolhidas para a análise eram correlacionadas ao preço, indicando que poderiam fornecer um bom ajuste. Isso se constatou logo no primeiro ajuste do modelo, realizado no Código 3.1, porém ainda havia problemas nos resíduos que precisam ser corrigidos. O segundo ajuste, presente no Código 3.2, fez as correções necessárias. O modelo final forneceu uma boa explicação da variabilidade do preço, com \\(R^2\\) = 0.956. Embora as covariáveis fossem correlacionadas entre si, não houve problema de multiconearidade. Os resultados mostram que nossa é razoável hipótese de que o ano de lançamento, o número de núcleos e a frequência do processador explicam a variação do preço médio. A Figura 3.7 mostra os valores preditos versus os valores observados do modelo ajustado no Código 3.2. Nota-se que o modelo de adequou bem aos dados, especialmente para os processadores de menor valor. Também, fica evidente a importância da segunda amostragem, uma vez que quase todos os valores maiores que 3,000 R$ foram obtidos através dela. Cabe ressaltar que não observamos todo o domínio da covariável nucleos e foi ajustado um polinômio de segundo grau para ela, por isso, esse modelo não é recomendado para a predição de preço para processadores com mais de 32 núcleos. Figura 3.7: Valores preditos versus valores observados, para o segundo modelo ajustado. "],["conclusão.html", "4 Conclusão 4.1 Trabalhos futuros", " 4 Conclusão A partir do presente estudo, podemos concluir: os modelos de regressão são ferramentas extramamente versateís e úteis não somente para predição de valores, mas para a explicação do comportanto de uma variável em função de outras; a segunda amostragem na etapa de coleta de dados foi primordial para um melhor ajuste do modelo; a presença de diversos pontos influentes demandou a utilização da técnica de regressão robusta de forma a minimizar os efeitos dos mesmos; no geral, o modelo apresentou um bom ajuste com \\(R^2\\) = 0.95, porém para predições deve ser utilizado com cautela pois devido ao grau do polinômio na variável nucleos, as predições serão melhores no domínio observado (1 até 32 núcleos). 4.1 Trabalhos futuros Houve uma mudança de layout do site após a segunda amostragem. O novo layout contém elementos de javascript para renderizar as especificações dos produtos. Os códigos para a obtenção dos dados no site se tornaram obsoletos, contudo, ainda é possível coletar os dados utilizando web scraping utilizando outras técnicas. O preço desses componentes são sensíveis aos novos lançamentos e ao câmbio, por isso, recomendados cautela em agregar novos dados a estes. Na Figura 4.1 podemos ver que as marcas Intel e AMD estão utlizando estratégias distintas nos processadores mais recentes. A Intel está apostando em processadores com menos núcleos, porém com uma alta frequência, isso pode ser visto, por exemplo, na décima geração das linhas da marca. Enquanto que a AMD está apostando em mais núcleos de processadores com uma menor frequência do que os processadores da Intel. Isso fica claro na linha dos Threadrippers que possuí processadores com mais de 60 núcleos de processamento. Especificamente para essa linha, não encontramos mais que 5 anúncios deles. Devido a seu alto valor, eles são encontrados em grandes sites que não anunciam no market place. Caso tivéssemos observado mais anúncios dessas linhas acreditamos que utilizar a marca do processador como covariável dummy seria suficiente para captar essa diferença de estratégias. Um desenvolvimento futuro deste trabalho seria coleta dados voltada para as linhas mais recentes das marcas. Ou seja, não somente no site que coletamos, mas também em outros grandes sites que não têm anúncios no market place. Figura 4.1: Covariáveis do modelo por marca. "],["anexos.html", "5 Anexos 5.1 Medidas de influência 5.2 Seleção de modelos 5.3 Intervalo de confiança para os parâmetros", " 5 Anexos Aqui estão algumas informações auxiliares que utilizamos para a construção do trabalho. 5.1 Medidas de influência im1 &lt;- influence.measures(fit) im2 &lt;- influence.measures(fit2) summary(im1) ## Potentially influential observations of ## lm(formula = Preco^0.2 ~ poly(Freq, 3) + poly(Nucleos, 2) + poly(Ano, 3), data = dt) : ## ## dfb.1_ dfb.p(F,3)1 dfb.p(F,3)2 dfb.p(F,3)3 dfb.p(N,2)1 dfb.p(N,2)2 ## 2 -0.10 -0.04 0.03 0.06 0.11 -0.08 ## 9 0.10 -0.09 0.09 0.14 -0.04 0.04 ## 52 0.10 0.09 -0.02 -0.08 -0.06 0.02 ## 64 0.11 -0.15 -0.06 0.12 0.16 -0.16 ## 65 -0.10 -0.01 0.04 0.08 0.03 0.00 ## 94 -0.10 0.10 -0.11 -0.08 0.00 -0.02 ## 149 -0.01 0.01 -0.04 0.03 0.00 0.00 ## 151 0.14 0.17 -0.05 -0.15 -0.08 0.03 ## 152 0.05 -0.09 0.20 -0.13 -0.01 0.02 ## 153 0.02 -0.01 0.07 -0.09 -0.01 0.01 ## 156 -0.05 -0.07 0.14 -0.14 0.02 -0.02 ## 158 -0.17 -0.29 0.70 -0.77 0.05 -0.03 ## 159 0.04 -0.07 0.18 -0.13 -0.01 0.02 ## 163 0.01 -0.02 0.00 0.01 0.02 -0.02 ## 185 -0.05 -0.07 0.14 -0.14 0.02 -0.02 ## 219 -0.12 -0.16 0.15 0.20 -0.06 0.10 ## 267 -0.10 0.06 0.08 0.04 -0.10 0.15 ## 270 0.04 0.03 0.01 -0.01 0.13 0.19 ## 276 -0.16 -0.20 0.20 0.26 -0.08 0.13 ## 284 0.13 -0.05 -0.05 0.15 0.04 -0.02 ## 285 0.13 -0.05 -0.05 0.14 0.04 -0.02 ## 288 0.13 -0.05 -0.05 0.14 0.04 -0.02 ## 307 0.02 0.01 0.00 0.03 -0.01 0.01 ## 321 0.00 0.00 0.00 0.00 0.00 0.00 ## 325 -0.03 0.01 -0.05 0.06 0.01 0.00 ## 332 -0.07 -0.01 -0.35 0.53 0.10 -0.06 ## 338 -0.05 -0.04 -0.01 0.01 -0.16 -0.24 ## 346 0.02 0.01 0.00 0.03 -0.01 0.01 ## 406 0.03 -0.09 -0.05 0.01 0.15 -0.11 ## 486 0.11 -0.01 -0.04 -0.09 0.02 -0.03 ## 489 -0.01 0.02 0.01 0.00 -0.05 0.01 ## 497 0.04 0.03 0.01 -0.01 0.13 0.19 ## 500 0.04 0.03 0.01 -0.01 0.13 0.19 ## 501 -0.05 -0.04 -0.01 0.01 -0.16 -0.24 ## 503 0.04 0.03 0.01 -0.01 0.13 0.19 ## dfb.p(A,3)1 dfb.p(A,3)2 dfb.p(A,3)3 dffit cov.r cook.d hat ## 2 -0.06 -0.04 0.00 -0.19 0.93_* 0.00 0.01 ## 9 0.12 -0.11 -0.11 0.29 0.94_* 0.01 0.02 ## 52 -0.10 -0.12 -0.05 0.23 0.93_* 0.01 0.01 ## 64 -0.09 0.11 0.08 0.36 0.94_* 0.01 0.02 ## 65 -0.02 -0.02 0.00 -0.16 0.93_* 0.00 0.00 ## 94 -0.06 0.11 -0.06 -0.28 0.94_* 0.01 0.01 ## 149 -0.01 0.02 -0.02 -0.06 1.13_* 0.00 0.10_* ## 151 -0.21 -0.18 0.01 0.35 0.85_* 0.01 0.01 ## 152 0.06 -0.12 0.13 0.29 1.06_* 0.01 0.06_* ## 153 -0.01 0.00 0.00 0.14 1.19_* 0.00 0.14_* ## 156 0.13 -0.26 0.16 -0.34 1.12_* 0.01 0.11_* ## 158 0.58 -1.28_* 1.09_* -1.75_* 1.06_* 0.34 0.21_* ## 159 0.06 -0.13 0.10 0.25 1.11_* 0.01 0.10_* ## 163 -0.01 0.02 -0.01 0.05 1.06_* 0.00 0.04 ## 185 0.13 -0.26 0.16 -0.34 1.12_* 0.01 0.11_* ## 219 0.35 0.10 -0.15 -0.44_* 0.91_* 0.02 0.02 ## 267 0.03 0.04 0.08 -0.23 0.93_* 0.01 0.01 ## 270 0.01 0.00 0.00 0.35 1.18_* 0.01 0.15_* ## 276 0.45 0.13 -0.20 -0.57_* 0.82_* 0.04 0.02 ## 284 -0.14 0.26 0.02 0.45_* 0.89_* 0.02 0.02 ## 285 -0.13 0.25 0.01 0.43_* 0.91_* 0.02 0.02 ## 288 -0.13 0.25 0.01 0.43_* 0.91_* 0.02 0.02 ## 307 -0.04 0.12 -0.12 0.20 1.17_* 0.00 0.13_* ## 321 0.00 0.00 0.00 -0.01 1.14_* 0.00 0.11_* ## 325 0.03 -0.08 0.10 -0.23 1.18_* 0.01 0.15_* ## 332 0.08 -0.02 0.12 -0.85_* 1.36_* 0.08 0.28_* ## 338 -0.01 0.00 -0.01 -0.43_* 1.17_* 0.02 0.15_* ## 346 -0.04 0.12 -0.12 0.20 1.17_* 0.00 0.13_* ## 406 -0.01 0.00 -0.03 0.17 1.05_* 0.00 0.04 ## 486 0.03 0.07 0.13 0.23 0.93_* 0.01 0.01 ## 489 0.00 0.00 0.01 -0.06 1.07_* 0.00 0.05_* ## 497 0.01 0.00 0.00 0.35 1.18_* 0.01 0.15_* ## 500 0.01 0.00 0.00 0.35 1.18_* 0.01 0.15_* ## 501 -0.01 0.00 -0.01 -0.43_* 1.17_* 0.02 0.15_* ## 503 0.01 0.00 0.00 0.35 1.18_* 0.01 0.15_* summary(im2) ## Potentially influential observations of ## rlm(formula = Preco^0.2 ~ poly(Freq, 3) + poly(Nucleos, 2) + poly(Ano, 3), data = dt, psi = MASS::psi.bisquare) : ## ## dfb.1_ dfb.p(F,3)1 dfb.p(F,3)2 dfb.p(F,3)3 dfb.p(N,2)1 dfb.p(N,2)2 ## 149 0.00 0.00 -0.01 0.01 0.00 0.00 ## 152 0.06 -0.10 0.23 -0.15 -0.01 0.02 ## 153 0.02 -0.01 0.07 -0.09 -0.01 0.01 ## 156 -0.06 -0.08 0.18 -0.18 0.02 -0.02 ## 158 -0.08 -0.13 0.33 -0.36 0.02 -0.01 ## 159 0.04 -0.09 0.24 -0.16 -0.01 0.02 ## 185 -0.06 -0.08 0.18 -0.18 0.02 -0.02 ## 270 0.04 0.03 0.01 -0.01 0.13 0.19 ## 307 0.02 0.01 -0.02 0.05 -0.01 0.01 ## 321 0.00 0.00 0.01 -0.01 0.00 0.00 ## 325 -0.03 0.01 -0.05 0.05 0.01 0.00 ## 332 -0.07 -0.02 -0.33 0.49 0.10 -0.07 ## 338 -0.05 -0.04 -0.01 0.01 -0.16 -0.23 ## 346 0.02 0.01 -0.02 0.05 -0.01 0.01 ## 489 -0.01 0.03 0.02 -0.01 -0.06 0.02 ## 497 0.04 0.03 0.01 -0.01 0.13 0.19 ## 500 0.04 0.03 0.01 -0.01 0.13 0.19 ## 501 -0.05 -0.04 -0.01 0.01 -0.16 -0.23 ## 503 0.04 0.03 0.01 -0.01 0.13 0.19 ## dfb.p(A,3)1 dfb.p(A,3)2 dfb.p(A,3)3 dffit cov.r cook.d hat ## 149 0.00 0.01 -0.01 -0.01 NA NA 0.12_* ## 152 0.07 -0.15 0.15 0.32 NA NA 0.06_* ## 153 -0.01 0.00 0.00 0.15 NA NA 0.15_* ## 156 0.16 -0.32 0.21 -0.40 NA NA 0.13_* ## 158 0.27 -0.58 0.49 -0.75_* NA NA 0.05_* ## 159 0.09 -0.18 0.14 0.32 NA NA 0.10_* ## 185 0.16 -0.32 0.21 -0.40 NA NA 0.13_* ## 270 0.01 0.00 0.00 0.35 NA NA 0.15_* ## 307 -0.04 0.13 -0.13 0.20 NA NA 0.17_* ## 321 0.00 0.00 0.00 0.02 NA NA 0.12_* ## 325 0.05 -0.11 0.13 -0.28 NA NA 0.16_* ## 332 0.08 -0.03 0.11 -0.82_* NA NA 0.25_* ## 338 -0.01 0.00 -0.01 -0.42_* NA NA 0.14_* ## 346 -0.04 0.13 -0.13 0.20 NA NA 0.17_* ## 489 0.00 0.00 0.01 -0.07 NA NA 0.06_* ## 497 0.01 0.00 0.00 0.35 NA NA 0.15_* ## 500 0.01 0.00 0.00 0.35 NA NA 0.15_* ## 501 -0.01 0.00 -0.01 -0.42_* NA NA 0.14_* ## 503 0.01 0.00 0.00 0.35 NA NA 0.15_* 5.2 Seleção de modelos m0 &lt;- lm(Preco^0.2 ~ Freq + Nucleos + Ano, data = dt) m1 &lt;- lm(Preco^0.2 ~ poly(Freq, 3) + poly(Nucleos, 2) + poly(Ano, 2), data = dt) m2 &lt;- lm(Preco^0.2 ~ poly(Freq, 3) + poly(Nucleos, 2) + poly(Ano, 3), data = dt) m3 &lt;- lm(Preco^0.2 ~ poly(Freq, 2) + poly(Nucleos, 2) + poly(Ano, 3), data = dt) m4 &lt;- lm(Preco^0.2 ~ poly(Freq, 2) + poly(Nucleos, 2) + poly(Ano, 2), data = dt) m5 &lt;- lm(Preco^0.2 ~ poly(Freq, 3) + log(Nucleos) + poly(Ano, 3), data = dt) modl &lt;- list(m0 = m0, m2 = m2, m3 = m3, m4 = m4, m5 = m5) asbio::lm.select(modl) ## Model AIC ## 1 Preco^0.2 ~ Freq + Nucleos + Ano 58.963124 ## 2 Preco^0.2 ~ poly(Freq, 3) + poly(Nucleos, 2) + poly(Ano, 3) -152.409605 ## 3 Preco^0.2 ~ poly(Freq, 2) + poly(Nucleos, 2) + poly(Ano, 3) -143.497034 ## 4 Preco^0.2 ~ poly(Freq, 2) + poly(Nucleos, 2) + poly(Ano, 2) 6.914451 ## 5 Preco^0.2 ~ poly(Freq, 3) + log(Nucleos) + poly(Ano, 3) 9.424837 ## AICc BIC Cp PRESS ## 1 59.08123 80.17424 6.00000 33.85989 ## 2 -151.97223 -109.98737 -162.46795 22.51970 ## 3 -143.13989 -105.31702 -157.35405 22.90219 ## 4 7.19960 40.85224 -42.46363 30.66416 ## 5 9.78198 47.60485 -40.01107 30.98014 5.3 Intervalo de confiança para os parâmetros confint(fit) ## 2.5 % 97.5 % ## (Intercept) 4.1750555 4.2108322 ## poly(Freq, 3)1 8.1783715 10.0362985 ## poly(Freq, 3)2 0.1150404 1.1632064 ## poly(Freq, 3)3 -1.2827355 -0.3238632 ## poly(Nucleos, 2)1 10.8399391 12.0269515 ## poly(Nucleos, 2)2 -3.2304335 -1.9686814 ## poly(Ano, 3)1 2.9576532 4.4428560 ## poly(Ano, 3)2 -1.3264982 -0.3297843 ## poly(Ano, 3)3 -2.9588468 -2.0659883 confint.default(object = fit2, parm = names(coef(fit2))) ## 2.5 % 97.5 % ## (Intercept) 4.174172897 4.2101356 ## poly(Freq, 3)1 8.188739363 10.0563246 ## poly(Freq, 3)2 0.002955697 1.0565705 ## poly(Freq, 3)3 -1.333094060 -0.3692372 ## poly(Nucleos, 2)1 10.866668906 12.0598518 ## poly(Nucleos, 2)2 -3.291850005 -2.0235388 ## poly(Ano, 3)1 2.968596058 4.4615196 ## poly(Ano, 3)2 -1.290399071 -0.2885039 ## poly(Ano, 3)3 -3.087985687 -2.1904857 "],["bibliografia.html", "Bibliografia", " Bibliografia "]]
